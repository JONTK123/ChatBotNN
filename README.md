# ðŸ§  Token-Predict-API â€“ Preditor de Tokens de Rede Neural

Um **pequeno playground visual de LLM** construÃ­do com **PyTorch**, **FastAPI** e **JavaScript puro**.  
Ele *prediz o prÃ³ximo token (palavra)* dado os **Ãºltimos 4 tokens** de uma frase e transmite todos os detalhes do treinamento para o navegador em tempo real.

> **Apenas educacional** â€“ perfeito para demonstraÃ§Ãµes, codificaÃ§Ã£o ao vivo e para entender como as partes de um modelo de linguagem se encaixam.

---

## ðŸŽ¯  Objetivo

*   Desmistificar como os *pequenos* LLMs aprendem tokenâ€‘porâ€‘token  
*   Visualizar **embeddings, ativaÃ§Ãµes, deltas de pesos** durante o treinamento  
*   Misturar **tokenizaÃ§Ã£o feita manualmente** com um **tokenizador GPTâ€‘2 real**  
*   Fornecer uma base de cÃ³digo hackeÃ¡vel para experimentos e posts de blog  

---

## ðŸ“¦  Funcionalidades

| Categoria | Detalhes                                                                      |
|-----------|--------------------------------------------------------------------------------|
| **Modelo** | `MiniGPT` customizado (embeddings â†’ 1 ou 2 camadas ocultas â†’ logits de vocabulÃ¡rio) |
| **Visuais** | GrÃ¡fico de perda ao vivo, superfÃ­cie de perda 3D, matriz de confusÃ£o, tokens com mais erros |
| **Frontend** | HTML + JS simples (Plotly, Cytoscape.js, WebSockets)                           |
| **Treinamento** | Adam + CrossEntropy, Ã©pocas configurÃ¡veis, transmissÃ£o ao vivo de batches    |
| **Tokenizador** | Tokenizador GPTâ€‘2 (**HuggingFace**) + split manual para comparaÃ§Ã£o          |
| **API** | Endpoints FastAPI `/treinar`, `/tokenizar`, `/completar`, alÃ©m de WebSocket `/ws` |

---

## âš ï¸  LimitaÃ§Ãµes

* Prediz **apenas o prÃ³ximo token** â€“ sem geraÃ§Ã£o de texto completo  
* Janela de contexto fixa para **4 tokens**  
* Requer **â‰¥ 50 frases** e cerca de **100â€‘150 Ã©pocas** para aprendizado estÃ¡vel  
* Frontend Ã© deliberadamente **mÃ­nimo** (voltado para estudo)  
* NÃ£o estÃ¡ pronto para produÃ§Ã£o; espere erros para tokens raros ou desconhecidos  

---

## ðŸ’¡  Ideias para Melhoria

*   Estender o contexto para 6â€‘8 tokens  
*   Embeddings / camadas ocultas maiores  
*   Corpus de treinamento maior e mais diversificado  
*   Substituir camadas FF por blocos GRU / Transformer  
*   Gerar frases completas em vez de tokenâ€‘porâ€‘token  

---

## ðŸ§­  Fluxo do Sistema

1. Cole frases de treinamento â†’ clique em **â€œTokenizar!â€**  
2. O app exibe tanto os **tokens separados** quanto os **tokens GPTâ€‘2**  
3. Clique em **â€œTreinarâ€** â†’ grÃ¡ficos ao vivo e ativaÃ§Ãµes sÃ£o transmitidos via WebSocket  
4. Quando terminar, digite um prompt de 4 tokens e pressione **â€œCompletarâ€**  
5. A API retorna o prÃ³ximo token mais provÃ¡vel, renderizado instantaneamente  

---

## âœ¨  Exemplos de Prompts

| Prompt (`Ãºltimos 4 tokens`) | PrevisÃ£o ProvÃ¡vel |
|-----------------------------|-------------------|
| `eu gosto de comer`         | `maÃ§Ã£`, `banana`, â€¦ |
| `hoje o cÃ©u estÃ¡`           | `limpo`, `nublado`, â€¦ |
| `vocÃª precisa estudar`      | `mais`, `agora`, â€¦ |
| `ela gosta de pintar`       | `quadros`, `paredes` |

---

## ðŸ“‚  Mini Dataset (vocÃª pode trocar o seu prÃ³prio â€“ em qualquer idioma!!!!!!!)

```python
frases = [
    "eu gosto de comer maÃ§Ã£",
    "ela gosta de pintar quadros",
    "nÃ³s vamos ao parque amanhÃ£",
    "ele vai sair hoje Ã  tarde",
    "vocÃª precisa estudar agora",
    "hoje o cÃ©u estÃ¡ limpo",
    "amanhÃ£ o tempo estarÃ¡ frio",
    "nÃ³s queremos comprar uma casa",
    "vocÃª quer comprar um celular",
    "eles vÃ£o ao mercado cedo",
]
```
## ðŸ› InstalaÃ§Ã£o & Uso

### 1â€“Clonar

```python
git clone https://github.com/JONTK123/Token-Predict-API.git
cd ChatBotNN
```

### 2 â€“ DependÃªncias

```python
python -m venv .venv
# Windows  â†’  .venv\Scripts\activate
source .venv/bin/activate
pip install -r requirements.txt
```

### 3 â€“ Iniciar a API

```python
uvicorn backend.nn:app --reload
```

### 4 â€“ Abrir o Frontâ€‘End

Basta abrir frontend/index.html no seu navegador.
Cole frases â†’ Tokenize â†’ Treine â†’ brinque com as previsÃµes

### 5 - Requirements.txt

```python
fastapi
uvicorn
torch
transformers
scikit-learn
matplotlib
numpy
anyio
```

## ðŸ”Como Funciona

1. TokenizaÃ§Ã£o â€“ Tokenizador GPTâ€‘2 (HuggingFace) + .split() ingÃªnuo para comparaÃ§Ã£o lado a lado
2. GeraÃ§Ã£o de pares â€“ para cada frase: Entrada = primeiros N tokens â†’ RÃ³tulo = o prÃ³ximo token
3. Modelo â€“ embeddings â†’ camada(s) oculta(s) â†’ logits de tamanho do vocabulÃ¡rio
4. Loop de treinamento â€“ Adam + CrossEntropy, progresso ao vivo enviado via WebSocket
5. InferÃªncia â€“ forneÃ§a 4 tokens, a API retorna argmax(logits) como o prÃ³ximo token previsto

## ðŸ§  Sobre

ConstruÃ­do por [@Thiago / JONTK123] para aprender e ensinar:
Linkedin -> https://www.linkedin.com/in/thiago-luiz-fossa-26b440276/?locale=pt_BR
- Fundamentos de redes neurais
- Camadas de embedding e peculiaridades da tokenizaÃ§Ã£o
- Pipelines de treinamento PyTorch
- Comportamento de Miniâ€‘LLM em conjuntos de dados pequenos
- TokenizaÃ§Ã£o e embeddings
- VisualizaÃ§Ã£o de ativaÃ§Ãµes e pesos
- InterpretaÃ§Ã£o de matrizes de confusÃ£o
- AnÃ¡lise de erros e tokens mais provÃ¡veis
- Uso de WebSockets para streaming em tempo real
- IntegraÃ§Ã£o de front-end e back-end com FastAPI
- CriaÃ§Ã£o de grÃ¡ficos interativos com Plotly
- ManipulaÃ§Ã£o de dados com NumPy e Matplotlib
- Uso de bibliotecas de aprendizado de mÃ¡quina como Scikit-learn
- CriaÃ§Ã£o de APIs RESTful com FastAPI
- Desenvolvimento de aplicaÃ§Ãµes web com HTML e JavaScript

## ðŸš§ Aviso

Este repositÃ³rio **nÃ£o estÃ¡ pronto para produÃ§Ã£o**.
As previsÃµes podem estar erradas ou tendenciosas, especialmente para palavras desconhecidas.
Ele existe puramente para aprendizado, experimentaÃ§Ã£o e intuiÃ§Ã£o visual.
Pull requests, problemas e discussÃµes sÃ£o bem-vindos â€“ divirta-se.


# ðŸ§  Token-Predict-API â€“ Neuralâ€‘Network TokenPredictor

A **tiny, visual LLM playground** built with **PyTorch**, **FastAPI** and vanilla **JavaScript**.  
It *predicts the next token (word)* given the **last 4 tokens** of a sentence and streams all training internals to the browser in realâ€‘time.

> **Educational only** â€“ perfect for demos, live coding, and understanding how languageâ€‘model pieces fit together.

---

## ðŸŽ¯  Purpose

*   Deâ€‘mystify how *small* LLMs learn tokenâ€‘byâ€‘token  
*   Visualise **embeddings, activations, weight deltas** while training  
*   Mix **handâ€‘made tokenisation** with a real **GPTâ€‘2 tokenizer**  
*   Provide a hackable codeâ€‘base for experiments and blog posts  

---

## ðŸ“¦  Features

| Category | Details                                                                        |
|----------|--------------------------------------------------------------------------------|
| **Model** | Custom `MiniGPT` (embeddings â†’ 1 or 2 hidden layers â†’ vocab logits)            |
| **Visuals** | Live loss lineâ€‘chart, 3â€‘D loss surface, confusion matrix, topâ€‘error tokens     |
| **Frontend** | Plain HTML+ JS (Plotly, Cytoscape.js, WebSockets)                              |
| **Training** | Adam+CrossEntropy, configurable epochs, live batch streaming                   |
| **Tokeniser** | GPTâ€‘2 tokenizer (**HuggingFace**) + manual split for comparison                |
| **API** | FastAPI endpoints `/treinar`, `/tokenizar`, `/completar`, plus WebSocket `/ws` |

---

## âš ï¸  Limitations

* Predicts **only the next token** â€“ no full text generation  
* Context window hardâ€‘coded to **4 tokens**  
* Needs **â‰¥ 50 phrases** and around **100â€‘150 epochs** for stable learning  
* Frontend is deliberately **minimal** (studyâ€‘oriented)  
* Not productionâ€‘ready; expect mistakes for rare / unseen tokens  

---

## ðŸ’¡  Ideas for Improvement

*   Extend context to 6â€‘8 tokens  
*   Wider embeddings / hidden layers  
*   Larger, more diverse training corpora  
*   Replace FFâ€‘layers with GRU / Transformer blocks  
*   Generate full sentences instead of tokenâ€‘byâ€‘token  

---

## ðŸ§­  System Flow

1. Paste training phrases â†’ click **â€œTokenise!â€**  
2. App shows both **split tokens** and **GPTâ€‘2 tokens**  
3. Click **â€œTrainâ€** â†’ live graphs & activations stream via WebSocket  
4. When done, type a 4â€‘token prompt and press **â€œCompleteâ€**  
5. API returns the most probable next token, rendered instantly  

---

## âœ¨  Example Prompts

| Prompt (`last 4 tokens`) | Likely Prediction |
|--------------------------|-------------------|
| `eu gosto de comer`      | `maÃ§Ã£`, `banana`, â€¦ |
| `hoje o cÃ©u estÃ¡`        | `limpo`, `nublado`, â€¦ |
| `vocÃª precisa estudar`   | `mais`, `agora`, â€¦ |
| `ela gosta de pintar`    | `quadros`, `paredes` |

---

## ðŸ“‚  Mini Dataset (you can swap your own - at any language!!!!!!!)

```python
frases = [
    "eu gosto de comer maÃ§Ã£",
    "ela gosta de pintar quadros",
    "nÃ³s vamos ao parque amanhÃ£",
    "ele vai sair hoje Ã  tarde",
    "vocÃª precisa estudar agora",
    "hoje o cÃ©u estÃ¡ limpo",
    "amanhÃ£ o tempo estarÃ¡ frio",
    "nÃ³s queremos comprar uma casa",
    "vocÃª quer comprar um celular",
    "eles vÃ£o ao mercado cedo",
]
```

## ðŸ› Installation & Usage

###1â€“Clone

```python
git clone https://github.com/JONTK123/Token-Predict-API.git
cd ChatBotNN
```

### 2 â€“ Dependencies

```python
python -m venv .venv
# Windows  â†’  .venv\Scripts\activate
source .venv/bin/activate
pip install -r requirements.txt
```

### 3 â€“ Start the API

```python
uvicorn backend.nn:app --reload
```

### 4 â€“ Open the Frontâ€‘End

Simply open frontend/index.html in your browser.
Paste sentences â†’ Tokenise â†’ Train â†’ play with predictions

###5 - Requirements.txt

```python
fastapi
uvicorn
torch
transformers
scikit-learn
matplotlib
numpy
anyio
```

## ðŸ”How It Works

1. Tokenisation â€“ GPTâ€‘2 tokenizer (HuggingFace) + naive .split() for sideâ€‘byâ€‘side comparison
2. Pair generation â€“ for every sentence:
Input = first N tokens â†’ Label = the next token
3. Model â€“ embeddings â†’ hidden layer(s) â†’ vocabâ€‘size logits 
4. Training loop â€“ Adam + CrossEntropy, live progress pushed via WebSocket
5. Inference â€“ give 4 tokens, API returns argmax(logits) as the predicted next token

## ðŸ§  About

Built by [@Thiago / JONTK123] to learn & teach:
Linkedin -> https://www.linkedin.com/in/thiago-luiz-fossa-26b440276/?locale=pt_BR

- Neuralâ€‘network fundamentals
- Embedding layers and tokenisation quirks
- PyTorch training pipelines
- Miniâ€‘LLM behaviour on tiny datasets
## ðŸš§ Disclaimer

This repository **is not production-ready**.  
Predictions may be wrong or biased, especially for unseen words.  
It exists purely for learning, experimentation, and visual intuition.

Pull requests, issues, and discussions are welcome â€“ have fun.